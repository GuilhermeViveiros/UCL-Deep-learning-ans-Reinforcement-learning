{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL_assignment_4.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1a1ONHRz5bcd2rJyLUD53OUMR8npSp0QZ",
          "timestamp": 1522325021849
        },
        {
          "file_id": "1Ldj742iIDtvjYKKwENvrpTQ3Hm2wrqIg",
          "timestamp": 1521476023411
        },
        {
          "file_id": "1FwMxkDPkt68fxovrMmmWwm6ohYvX2wt1",
          "timestamp": 1517660129183
        },
        {
          "file_id": "1wwTq5nociiMHUb26jxrvZvGN6l11xV5o",
          "timestamp": 1517174839485
        },
        {
          "file_id": "1_gJNoj9wG4mnigscGRAcZx7RHix3HCjG",
          "timestamp": 1515086437469
        },
        {
          "file_id": "1hcBeMVfaSh8g1R2ujtmxOSHoxJ8xYkaW",
          "timestamp": 1511098107887
        }
      ],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "pYs6LMEbNqoQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RL homework 4\n",
        "\n",
        "-------------------------------\n",
        "\n",
        "\n",
        "**Name:** Wu Zhi\n",
        "\n",
        "**SN:** 17040772\n",
        "\n",
        "-----------------------------------\n",
        "\n",
        "\n",
        "**Start date:** *29th March 2018*\n",
        "\n",
        "**Due date:** *19th April 2018, 4:55 pm*\n",
        "\n",
        "------------------------------------\n",
        "\n",
        "## How to Submit\n",
        "\n",
        "When you have completed the exercises and everything has finsihed running, click on 'File' in the menu-bar and then 'Download .ipynb'. This file must be submitted to Moodle named as **studentnumber_RL_hw4.ipynb** before the deadline above.\n",
        "\n",
        "Also send a **sharable link** to the notebook at the following email: ucl.coursework.submit@gmail.com. You can also make it sharable via link to everyone, up to you.\n",
        "\n",
        "Please compile all results and all answers to the understanding questions into a PDF. Name convention: **studentnumber_RL_hw4.pdf**. Do not include any of the code (we will use the notebook for that). \n",
        "\n",
        "**Page limit: 10 pg **\n"
      ]
    },
    {
      "metadata": {
        "id": "9v_SYckYfv5G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Context\n",
        "\n",
        "In this assignment, we will take a first look at learning decisions from data.  For this, we will use the multi-armed bandit framework.\n",
        "\n",
        "## Background reading\n",
        "\n",
        "* Sutton and Barto (2018), Chapters 6-7 + 9-11"
      ]
    },
    {
      "metadata": {
        "id": "ztQEQvnKh2t6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ]
    },
    {
      "metadata": {
        "id": "qB0tQ4aiAaIu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import Useful Libraries"
      ]
    },
    {
      "metadata": {
        "id": "YzYtxi8Wh5SJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from collections import namedtuple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6NDhSYfSDcCC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Set options"
      ]
    },
    {
      "metadata": {
        "id": "Ps5OnkPmDbMX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.set_printoptions(precision=3, suppress=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cOu9RZY3AkF1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Helper functions"
      ]
    },
    {
      "metadata": {
        "id": "6EttQGJ1n5Zn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def run_experiment(env, agent, number_of_steps):\n",
        "    mean_reward = 0.\n",
        "    try:\n",
        "      action = agent.initial_action()\n",
        "    except AttributeError:\n",
        "      action = 0\n",
        "    for i in range(number_of_steps):\n",
        "      reward, discount, next_state = grid.step(action)\n",
        "      action = agent.step(reward, discount, next_state)\n",
        "      mean_reward += (reward - mean_reward)/(i + 1.)\n",
        "\n",
        "    return mean_reward\n",
        "\n",
        "map_from_action_to_subplot = lambda a: (2, 6, 8, 4)[a]\n",
        "map_from_action_to_name = lambda a: (\"up\", \"right\", \"down\", \"left\")[a]\n",
        "\n",
        "def plot_values(values, colormap='pink', vmin=None, vmax=None):\n",
        "  plt.imshow(values, interpolation=\"nearest\", cmap=colormap, vmin=vmin, vmax=vmax)\n",
        "  plt.yticks([])\n",
        "  plt.xticks([])\n",
        "  plt.colorbar(ticks=[vmin, vmax])\n",
        "\n",
        "def plot_action_values(action_values, vmin=None, vmax=None):\n",
        "  q = action_values\n",
        "  fig = plt.figure(figsize=(8, 8))\n",
        "  fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
        "  for a in [0, 1, 2, 3]:\n",
        "    plt.subplot(3, 3, map_from_action_to_subplot(a))\n",
        "    plot_values(q[..., a], vmin=vmin, vmax=vmax)\n",
        "    action_name = map_from_action_to_name(a)\n",
        "    plt.title(r\"$q(s, \\mathrm{\" + action_name + r\"})$\")\n",
        "    \n",
        "  plt.subplot(3, 3, 5)\n",
        "  v = 0.9 * np.max(q, axis=-1) + 0.1 * np.mean(q, axis=-1)\n",
        "  plot_values(v, colormap='summer', vmin=vmin, vmax=vmax)\n",
        "  plt.title(\"$v(s)$\")\n",
        "\n",
        "\n",
        "def plot_rewards(xs, rewards, color):\n",
        "  mean = np.mean(rewards, axis=0)\n",
        "  p90 = np.percentile(rewards, 90, axis=0)\n",
        "  p10 = np.percentile(rewards, 10, axis=0)\n",
        "  plt.plot(xs, mean, color=color, alpha=0.6)\n",
        "  plt.fill_between(xs, p90, p10, color=color, alpha=0.3)\n",
        "  \n",
        "\n",
        "def parameter_study(parameter_values, parameter_name,\n",
        "  agent_constructor, env_constructor, color, repetitions=10, number_of_steps=int(1e4)):\n",
        "  mean_rewards = np.zeros((repetitions, len(parameter_values)))\n",
        "  greedy_rewards = np.zeros((repetitions, len(parameter_values)))\n",
        "  for rep in range(repetitions):\n",
        "    for i, p in enumerate(parameter_values):\n",
        "      env = env_constructor()\n",
        "      agent = agent_constructor()\n",
        "      if 'eps' in parameter_name:\n",
        "        agent.set_epsilon(p)\n",
        "      elif 'alpha' in parameter_name:\n",
        "        agent._step_size = p\n",
        "      else:\n",
        "        raise NameError(\"Unknown parameter_name: {}\".format(parameter_name))\n",
        "      mean_rewards[rep, i] = run_experiment(grid, agent, number_of_steps)\n",
        "      agent.set_epsilon(0.)\n",
        "      agent._step_size = 0.\n",
        "      greedy_rewards[rep, i] = run_experiment(grid, agent, number_of_steps//10)\n",
        "      del env\n",
        "      del agent\n",
        "\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plot_rewards(parameter_values, mean_rewards, color)\n",
        "  plt.yticks=([0, 1], [0, 1])\n",
        "  # plt.ylim((0, 1.5))\n",
        "  plt.ylabel(\"Average reward over first {} steps\".format(number_of_steps), size=12)\n",
        "  plt.xlabel(parameter_name, size=12)\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plot_rewards(parameter_values, greedy_rewards, color)\n",
        "  plt.yticks=([0, 1], [0, 1])\n",
        "  # plt.ylim((0, 1.5))\n",
        "  plt.ylabel(\"Final rewards, with greedy policy\".format(number_of_steps), size=12)\n",
        "  plt.xlabel(parameter_name, size=12)\n",
        "  \n",
        "def epsilon_greedy(q_values, epsilon):\n",
        "  if epsilon < np.random.random():\n",
        "    return np.argmax(q_values)\n",
        "  else:\n",
        "    return np.random.randint(np.array(q_values).shape[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zTJ3WYL8Y0GQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### A small MRP"
      ]
    },
    {
      "metadata": {
        "id": "iPnQLBHsYzdq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class SmallMRP(object):\n",
        "\n",
        "  def __init__(self, p=0.1):\n",
        "    self._state = 0\n",
        "    self._p = p\n",
        "\n",
        "  def get_state(self):\n",
        "    return self._state\n",
        "\n",
        "  def step(self):\n",
        "    reward = 0\n",
        "    discount = 1\n",
        "    if self._state == 0:\n",
        "      self._state = 1\n",
        "    else:\n",
        "      if np.random.random() < self._p:\n",
        "        self._state = 0\n",
        "        discount = 0\n",
        "      else:\n",
        "        self._state = 1\n",
        "\n",
        "    return reward, discount, self.get_obs()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HdojBKQ2CK9e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assignment 1 [50pts in total]\n",
        "\n",
        "We are going to analyze the simple Markov reward process (MRP - a MRP is an MDP without actions or, equivalently, with a single action in each state) defined in the code cell above.  It consists of two states.  The reward is zero everywhere.  When we are in state $s_0$, we always transition to $s_1$.  If we are in state $s_1$, there is a probability $p$ (which is set to 0.1 by default in the code above) of terminating, after which the next episode starts in $s_0$ again.  With a probability of $1 - p$, we transition from $s_1$ back to itself again.  The discount is $\\gamma = 1$ on non-terminal steps.\n",
        "\n",
        "#### [1pt] Question 1.1\n",
        "What is the optimal value in each state?\n",
        "\n",
        "**Answer**: The optimal value is 0 in each state.\n",
        "\n",
        "#### [1pt] Question 1.2\n",
        "Instead of a tabular representation, consider a single feature $\\phi$, which takes the values $\\phi(s_0) = 1$ and $\\phi(s_1) = 4$.  Now consider using linear function approximation, where we learn a value $\\theta$ such that $v_{\\theta}(s) = \\theta \\times \\phi(s) \\approx v(s)$, where $v(s)$ is the true value of state $s$.  What is the optimal value of $\\theta$?\n",
        "\n",
        "**Answer**: Because $v_{\\theta}(s) = \\theta * \\phi (s) \\approx v(s) = 0$, then $\\theta = 0$\n",
        "\n",
        "#### [8pts] Question 1.3\n",
        "Suppose $\\theta_0 = 1$, and suppose we update this parameter with TD(0) with a step size of $\\alpha = 0.1$.  What is the expected value of $\\mathbb{E}[ \\theta_T ]$ if we step through the MDP until it terminates after the first episode, as a function of $p$?  (Note that $T$ is random.)\n",
        "\n",
        "**Answer**:\n",
        "\n",
        "The updata equation is:\n",
        "$$\\triangle \\theta_t = \\alpha(R_{t+1} + \\gamma v_{\\theta}(s_{t+1} - v_{\\theta}(s_{t})))\\phi_t$$\n",
        "\n",
        "For the path $s_0 \\rightarrow s_1 \\rightarrow terminating$, the $\\theta _T$ is given by:\n",
        "\n",
        "$$\\triangle \\theta_0 = 0.1 * (0 + 1 * 1 * 4 - 1 * 1) * 1 = 0.3$$\n",
        "$$\\theta_1 = 1+0.3 = 1.3$$\n",
        "\n",
        "For the path $s_0 \\rightarrow s_1 \\rightarrow s_1\\rightarrow terminating$, the $\\theta _T$ is given by:\n",
        "\n",
        "$$\\triangle \\theta_1 = 0.1 * (0 + 1 * 1.3 * 4 - 1.3 * 4) * 1 = 0$$\n",
        "$$\\theta_1 = 1.3 + 0 = 1.3$$\n",
        "\n",
        "Thus, for path $s_0 \\rightarrow s_1 \\rightarrow  ... \\rightarrow s_1\\rightarrow terminating$, $\\theta _T = 1.3 (T>=1)$\n",
        "\n",
        "After terminating, the state move from $s_1$ to $s_0$, and the change for $\\theta_T$ is :\n",
        "\n",
        "$$\\triangle \\theta_T = 0.1 * (0 + 0 - \\theta_T * 4) * 4 = -1.6 \\theta_T$$\n",
        "$$\\triangle \\theta_{T + 1} = \\triangle \\theta_T  + (-1.6 \\theta_T) = -0.6 \\theta_T$$\n",
        "\n",
        "In this problem, $\\theta_T = 1.3 * -0.6 = -0.78$, and here the function is independent with p. Thus, the expectation is:\n",
        "\n",
        "$$\\mathbb{E}[ \\theta_T ] = -0.78$$\n",
        "\n",
        "#### [5pts] Question 1.3\n",
        "If $p=0.1$, how many episodes does it take, starting from $\\theta_0 = 1$, until $| v(s) - \\mathbb{E}[v_{\\theta}(s)] | < 0.5$ for all $s$, where the expectation is over the expected updates to $\\theta$?\n",
        "\n",
        "**Answer**:\n",
        "\n",
        " For each episode, the expectation of $\\theta$ is -0.78: $\\mathbb{E}[\\theta_{T+1}] = -0.78 * \\mathbb{E}[\\theta_{T}]$\n",
        " \n",
        " For the state $s_1$, we need make sure that:\n",
        " \n",
        " $$| v(s_1) - \\mathbb{E}[v_{\\theta}(s_1)] | < 0.5$$\n",
        " $$|0 - 4 * (-0.78)^n|<0.5$$\n",
        " \n",
        " Then for an integer $n$, we can get the answer: $n \\geq 9$\n",
        "\n",
        " For the state $s_0$, we need make sure that:\n",
        " \n",
        " $$| v(s_0) - \\mathbb{E}[v_{\\theta}(s_0)] | < 0.5$$\n",
        " $$|0- 1 * (-0.78)^n|<0.5$$\n",
        " \n",
        "So, we can get the answer: $n \\geq 3$\n",
        " \n",
        "Overall, after at least **9** episodes $| v(s) - \\mathbb{E}[v_{\\theta}(s)] | < 0.5$.\n",
        "\n",
        "#### Synchronous updates\n",
        "Consider the following algorithm: we use TD to update the parameters, but instead of using the online data, we assume we can actively sample a transition from both states.  We then update $\\theta$ using both samples:\n",
        "$$\n",
        "\\theta_{n+1} = \\theta_n + \\alpha \\delta_0 \\phi(s_0) + \\alpha \\delta_1 \\phi(s_1) \\,,\n",
        "$$\n",
        "where $\\delta_i$ is a sampled one-step TD error when transitioning from state $s_i$.\n",
        "\n",
        "#### [10pts] Question 1.4\n",
        "\n",
        "What is the value of $\\mathbb{E}[\\theta_n]$, as a function of $n$ and $p$?\n",
        "\n",
        "**Answer**: \n",
        "The expectation of $\\theta_{n+1}$ is: \n",
        "\n",
        "$$\\mathbb{E}[\\theta_{n+1}] = \\mathbb{E}[\\theta_{n}] + \\alpha \\phi (s_0) \\mathbb{E}[\\delta_0] + \\alpha \\phi (s_1) \\mathbb{E}[\\delta_1]$$\n",
        " $$where \\delta = r + \\gamma v_{\\theta}(s_{t+1}) -v_{\\theta}(s_{t})$$\n",
        "\n",
        "Then we can calaulate expectation of $\\delta_0$ and $\\delta_1$:\n",
        "\n",
        "$$\\mathbb{E}[\\delta_0] = (\\phi (s_1) - \\phi (s_0))\\mathbb{E}[\\theta_{n}] = 3\\mathbb{E}[\\theta_{n}]$$\n",
        "$$\\mathbb{E}[\\delta_1] = p*(0 - \\phi (s_1)\\mathbb{E}[\\theta_{n}])+ (1-p) * 0 = -4p\\mathbb{E}[\\theta_{n}]$$\n",
        "\n",
        "Thus the update equation is:\n",
        "\n",
        "$$\\mathbb{E}[\\theta_{n+1}] = \\mathbb{E}[\\theta_{n}] + 3\\mathbb{E}[\\theta_{n}] + 4 * (-4p\\mathbb{E}[\\theta_{n}]) = (1 + 3\\alpha - 16p\\alpha)\\mathbb{E}[\\theta_{n}]$$\n",
        "\n",
        "Assuming start from $\\theta_0$, the value of $\\mathbb{E}[\\theta_n]$ can be written as:\n",
        "\n",
        "$$ \\mathbb{E}[\\theta_{n}] = (1 + 3\\alpha - 16\\alpha p)^n \\theta_0$$\n",
        "\n",
        "#### [5pts] Question 1.5\n",
        "\n",
        "For which values of $p$ does not $\\theta$ converge to the optimal solution?\n",
        "\n",
        "**Answer**: The value of $\\mathbb{E}[\\theta_n]$ can be written as:\n",
        "\n",
        "$$ \\mathbb{E}[\\theta_{n}] = (1 + 3\\alpha - 16\\alpha p)^n \\theta_0$$\n",
        " \n",
        " If $\\theta$ converge to the optimal solution which is 0, the requirement is:\n",
        "\n",
        " $$(1 + 3\\alpha - 16\\alpha p)^n \\simeq 0$$\n",
        " \n",
        " Thus,  for $\\theta$ does not converge to 0, the requirement is\n",
        " $$|1 + 3\\alpha - 16\\alpha p| \\geq 1$$\n",
        " \n",
        " The range of value of p is:\n",
        " \n",
        " $$\\frac{2 + 3\\alpha}{16 \\alpha} \\leq p \\leq \\frac{3}{16}$$\n",
        " \n",
        "Hence, $\\alpha = 0.1$ here, so $\\frac{2 + 3\\alpha}{16 \\alpha} = \\frac{23}{16}$, so the final answer is \n",
        "\n",
        "$$p \\leq \\frac{3}{16}$$\n",
        " \n",
        "\n",
        "#### [10pts] Question 1.5\n",
        "Why doesn't it?  TD is known to converge, with linear function approximation, under certain assumptions.  Explain for this concrete case why the algorithm does not converge, and explain which general assumption is violated that would otherwise ensure convergence of linear TD (in at most 200 words).\n",
        "\n",
        "**Answer**: \n",
        "\n",
        "$$\\theta_{n+1} = \\begin{cases}\n",
        "&\\theta_n + \\frac{1}{10}(3\\theta_n-16\\theta_n) = \\theta_n -1.3\\theta_n & \\text{with } p \\\\\n",
        "&\\theta_n + \\frac{1}{10}(3\\theta_n) = \\theta_n + 0.3\\theta_n & \\text{with } 1-p\n",
        "\\end{cases}$$\n",
        "So $$\\mathbb{E}[\\theta_{n+1}\\mid \\theta_n] = \\theta_n - A \\theta_n = (1-A)\\theta_n$$ $$where A = 1.3p - 0.3(1-p)=-0.3+1.6p$$\n",
        "\n",
        "In general linear TD(0) algorithm, the convergence is guaranteed if $\\mathbf{A}$ (with shape $n$ by $n$, where $n$ is the dimension of the feature space, in our case $n=1$ and we have merge the step size $\\alpha$ into $A$ above) is positive definite so that in $(\\mathbf{I}-\\alpha\\mathbf{A})\\theta_n$, $\\theta_n$ will be reduced toward zero and stability is assured. \n",
        "\n",
        "In the above case, the convergence is guaranteed if $A>0$ (actually we would also require $A<2$ but since $p\\leq1$ we can ignore this), that is $p>\\frac{3}{16}$. So when $p\\leq\\frac{3}{16}$, the assumption of the positive definiteness of $A$ will be violated, resulting in divergence.\n",
        "\n",
        "#### [10pts] Question 1.5\n",
        "Describe a way to change the algorithm to obtain convergence of $\\theta$, for any $p$, without changing the sampling or the value function (which should remain as $v_{\\theta}(s) = \\theta \\times \\phi(s)$).  Note that the sampling is not sequential, so for instance you cannot add memory of previous states.  (At most 200 words.)\n",
        "\n",
        "**Answer**: \n",
        "\n",
        "Convergence can be obtained by setting different step sizes the two samples in each step, now \n",
        "$$\\theta_{n+1} = \\theta_n + \\alpha_0 \\delta_0 \\phi(s_0) + \\alpha_1 \\delta_1 \\phi(s_1) \n",
        "$$ As before, $A = 16\\alpha_1p-3\\alpha_0$. Solve $0<A<2$ we have \n",
        "\n",
        "$$\\frac{3\\alpha_0}{16\\alpha_1}<p<\\frac{2+3\\alpha_0}{16\\alpha_1}$$ \n",
        "\n",
        "In order to have this inequality holds for all $p\\in(0,1]$, we can set $\\alpha_0$ and $\\alpha_1$ as finctions of $n$ such that \n",
        "\n",
        "$$\\lim_{n\\to\\infty}\\frac{3\\alpha_0(n)}{16\\alpha_1(n)}=0$$ and $$\\lim_{n\\to\\infty}\\frac{2+3\\alpha_0(n)}{16\\alpha_1(n)}\\geq1$$\n",
        "\n",
        "We can set $\\alpha_0(n)$ as a non-negative decreasing function of $n$ and $\\alpha_1(n)$ as an increasing function of $n$ with supremum $\\frac{2}{16}$, such that the two limits above will hold. Then the convergence is guaranteed whenever $p>0$. Note that we cannot reach convergence if $p=0$ as $\\theta_n$ will go to $\\infty$ as $n$ goes to $\\infty$.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "c4v8_c7XqsEo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assignment 2 [50pts in total + 10 BONUS pts]"
      ]
    },
    {
      "metadata": {
        "id": "ALrRR76eAd6u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### A grid world"
      ]
    },
    {
      "metadata": {
        "id": "YP97bVN3NuG8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class Grid(object):\n",
        "\n",
        "  def __init__(self, tabular=True, vision_size=1, noisy=False):\n",
        "    # -1: wall\n",
        "    # 0: empty, episode continues\n",
        "    # other: number indicates reward, episode will terminate\n",
        "    self._layout = np.array([\n",
        "      [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
        "      [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
        "      [-1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1],\n",
        "      [-1, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1],\n",
        "      [-1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1],\n",
        "      [-1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1],\n",
        "      [-1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1],\n",
        "      [-1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1],\n",
        "      [-1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1],\n",
        "      [-1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1],\n",
        "      [-1, -1, -1, -5, -1, -1, -1, -1, -6, -1, -1, -1, -1, 10, -1, -1, -1],\n",
        "      [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
        "      [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
        "    ])\n",
        "    self._start_state = (3, 2)\n",
        "    self._state = self._start_state\n",
        "    self._number_of_states = np.prod(np.shape(self._layout))\n",
        "    self._noisy = noisy\n",
        "    self._tabular = tabular\n",
        "    self._vision_size = vision_size\n",
        "\n",
        "  @property\n",
        "  def number_of_states(self):\n",
        "      return self._number_of_states\n",
        "    \n",
        "  def plot_grid(self):\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(self._layout != -1, interpolation=\"nearest\")\n",
        "    ax = plt.gca()\n",
        "    ax.grid(0)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.title(\"The grid\")\n",
        "    plt.text(2, 2, r\"$\\mathbf{S}$\", ha='center', va='center')\n",
        "    goal_y, goal_x = np.where(self._layout==10)\n",
        "    plt.text(goal_x, goal_y, r\"$\\mathbf{G}$\", ha='center', va='center')\n",
        "    goal_y, goal_x = np.where(self._layout==-5)\n",
        "    plt.text(goal_x, goal_y, r\"$\\mathbf{D}$\", ha='center', va='center')\n",
        "    goal_y, goal_x = np.where(self._layout==-6)\n",
        "    plt.text(goal_x, goal_y, r\"$\\mathbf{D}$\", ha='center', va='center')\n",
        "    h, w = self._layout.shape\n",
        "    for y in range(h-1):\n",
        "      plt.plot([-0.5, w-0.5], [y+0.5, y+0.5], '-k', lw=2)\n",
        "    for x in range(w-1):\n",
        "      plt.plot([x+0.5, x+0.5], [-0.5, h-0.5], '-k', lw=2)\n",
        "\n",
        "  def get_obs(self):\n",
        "    y, x = self._state\n",
        "    return self.get_obs_at(x, y)\n",
        "\n",
        "  def get_obs_at(self, x, y):\n",
        "    if self._tabular:\n",
        "      return y*self._layout.shape[1] + x\n",
        "    else:\n",
        "      v = self._vision_size\n",
        "      location = np.clip(-self._layout[y-v:y+v+1,x-v:x+v+1], 0, 1)\n",
        "      return location\n",
        "\n",
        "  def step(self, action):\n",
        "    y, x = self._state\n",
        "    \n",
        "    if action == 0:  # up\n",
        "      new_state = (y - 1, x)\n",
        "    elif action == 1:  # right\n",
        "      new_state = (y, x + 1)\n",
        "    elif action == 2:  # down\n",
        "      new_state = (y + 1, x)\n",
        "    elif action == 3:  # left\n",
        "      new_state = (y, x - 1)\n",
        "    else:\n",
        "      raise ValueError(\"Invalid action: {} is not 0, 1, 2, or 3.\".format(action))\n",
        "\n",
        "    new_y, new_x = new_state\n",
        "    discount = 0.98\n",
        "    if self._layout[new_y, new_x] == -1:  # wall\n",
        "      reward = -1\n",
        "      new_state = (y, x)\n",
        "    elif self._layout[new_y, new_x] != 0: # a goal\n",
        "      reward = self._layout[new_y, new_x]\n",
        "      discount = 0.\n",
        "      new_state = self._start_state\n",
        "    else:\n",
        "      reward = (new_y + new_x) / np.sum(self._layout.shape)\n",
        "    if self._noisy:\n",
        "      width = self._layout.shape[1]\n",
        "      reward += 2*np.random.normal(0, width - new_x + new_y)\n",
        "    \n",
        "    self._state = new_state\n",
        "\n",
        "    return reward, discount, self.get_obs()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UaGeLcsvixmt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The grid\n",
        "\n",
        "The cell below shows the `Grid` environment that we will use. Here `S` indicates the start state and `G` indicates the goal.  The agent has four possible actions: up, right, down, and left.  Rewards are: `-1` for bumping into a wall, `+10` for reaching the goal, and `(x + y)/(height + width)` otherwise, which encourages the agent to go right and down.  The episode ends when the agent reaches the goal.  At the end of the left-most two corridors, there are distractor 'goals' (marked `D`) that give a reward of $-5$ and $-6$, and then also terminate the episode.  The discount, on continuing steps, is $\\gamma = 0.98$.  Feel free to reference the implemetation of the `Grid` above, under the header \"a grid world\"."
      ]
    },
    {
      "metadata": {
        "id": "SlFuWFzIi5uB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "f6b4c4f0-1122-43cf-fdd7-3a6c8c34c157",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524099968760,
          "user_tz": -60,
          "elapsed": 620,
          "user": {
            "displayName": "JOY WU",
            "photoUrl": "//lh6.googleusercontent.com/-tPBEt0lFVJA/AAAAAAAAAAI/AAAAAAAABm0/dJFicuVmNrg/s50-c-k-no/photo.jpg",
            "userId": "118283881385645801877"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "grid = Grid()\n",
        "grid.plot_grid()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADICAYAAAAELGYKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkRYwhtACxhBawBhCCxhDaAFjCC1gzH8A6UVb6Pf+00oAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd3e76a84d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "MKfA7ifHvO-M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Implement agents\n",
        "**[10 pts]** In the next code cell, implement an agent that uses **tabular Sarsa** to learn action values.  The agent should act according to an $\\epsilon$-greedy policy with respect to its action values.\n",
        "\n",
        "The agent will be initialized with:\n",
        "```\n",
        "agent = Sarsa(number_of_states=grid._layout.size,\n",
        "              number_of_actions=4,\n",
        "              grid.get_obs())\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "u_hLSL8anhsv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class Sarsa(object):\n",
        "\n",
        "  def __init__(self, number_of_states, number_of_actions, initial_state, step_size=0.1):\n",
        "    \n",
        "    self.s = initial_state\n",
        "    self.lr = step_size\n",
        "    self.q = np.zeros((number_of_states, number_of_actions))\n",
        "    self.last_action = 0\n",
        "    \n",
        "  @property\n",
        "  def q_values(self):\n",
        "    return self.q\n",
        "\n",
        "  def step(self, r, g, s):\n",
        "    \n",
        "    next_a = epsilon_greedy(self.q[s,:], 0.1)\n",
        "    \n",
        "    self.q[self.s, self.last_action] +=  self.lr * (r + g * self.q[s, next_a] - self.q[self.s,self.last_action]) \n",
        " \n",
        "    self.s = s\n",
        "    self.last_action = next_a\n",
        "    \n",
        "    return self.last_action"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oMr_z0RZsHNj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**[20 pts]** Implement an agent that uses **neural Sarsa** to learn action values.  The agent should expect a nxn input which it should flatten into a vector, and then pass through a multi-layer perceptron with a single hidden layer with 100 hidden nodes and ReLU activations.  Each weight layer should also have a bias.  Initialize all weights uniformly randomly in $[-0.05, 0.05]$.\n",
        "\n",
        "```\n",
        "NeuralSarsa(number_of_features=(2*vision_size + 1)**2,\n",
        "            number_of_hidden=100,\n",
        "            number_of_actions=4,\n",
        "            initial_state=grid.get_obs(),\n",
        "            step_size=0.01)\n",
        "```\n",
        "\n",
        "The number `vision_size` will be either 1 or 2 below.  The input vector will be of size $(2v + 1)^2$, which will correspond to a square local view of the grid, centered on the agent, and of size $(2v + 1) \\times (2v + 1)$ (so either 3x3 or 5x5).\n",
        "\n",
        "You are allowed, but not mandated, to use TensorFlow to implement this agent.  (The network is small enough that you can also use numpy, but then you have to implement your own backprop.)  Please document the code clearly, especially on non-trivial operations."
      ]
    },
    {
      "metadata": {
        "id": "w5aUV7ILAHuN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class NeuralSarsa(object):\n",
        "\n",
        "  def __init__(self, number_of_features, number_of_hidden, number_of_actions, initial_state, step_size=0.01):\n",
        "    self._number_of_features = number_of_features\n",
        "    self._number_of_hidden = number_of_hidden\n",
        "    self._number_of_actions = number_of_actions\n",
        "    self._s = initial_state\n",
        "    self._a = 0\n",
        "    self._alpha = step_size\n",
        "    self.getgraph()\n",
        "    self.runsess()\n",
        "    \n",
        "  def q(self, obs):\n",
        "    # This function should give the vector of action values for observation obs\n",
        "    reshape = obs.reshape(1, -1)\n",
        "    q_s = self.sess.run(self.q_t1, feed_dict = {self.s_t1: reshape})\n",
        "    return q_s.reshape(4,)\n",
        "    \n",
        "  \n",
        "  def step(self, r, g, s):\n",
        "    # This function should return an action\n",
        "    \n",
        "    next_a = epsilon_greedy(self.q(s), 0.1)\n",
        "    feed_dict = {self.s_t: self._s, self.s_t1: s, self._r: r, self._g: g, self.a_t: self._a, self.a_t1: next_a}\n",
        "    self.sess.run(self.optimizer, feed_dict = feed_dict)\n",
        "    \n",
        "    self._s = s\n",
        "    self._a = next_a\n",
        "    \n",
        "    return self._a\n",
        "    \n",
        "    \n",
        "  def variable(self, a, b):\n",
        "    return tf.Variable(tf.random_uniform([a, b], -0.05, 0.05))\n",
        "  \n",
        "  def initial(self):\n",
        "    self.s_t = tf.placeholder(tf.int32, [None, None])\n",
        "    self.s_t1 = tf.placeholder(tf.int32, [None, None])\n",
        "    self.a_t = tf.placeholder(tf.int32, None) \n",
        "    self.a_t1 = tf.placeholder(tf.int32, None)\n",
        "    self._r = tf.placeholder(tf.float32, None)\n",
        "    self._g = tf.placeholder(tf.float32, None)\n",
        "    \n",
        "    self._w1 = self.variable(self._number_of_features, self._number_of_hidden)\n",
        "    self._b1 = self.variable(1, self._number_of_hidden)\n",
        "    self._w2 = self.variable(self._number_of_hidden, self._number_of_actions )\n",
        "    self._b2 = self.variable(1,self._number_of_actions )\n",
        "    \n",
        "  \n",
        "  def neuralnet(self, x):\n",
        "    flatten = tf.cast(tf.reshape(x, [1,-1]), tf.float32)\n",
        "    hidden = tf.nn.relu(tf.matmul(flatten, self._w1) + self._b1)\n",
        "    output = tf.matmul(hidden, self._w2) + self._b2\n",
        "    return output\n",
        "    \n",
        "  def runsess(self):\n",
        "    self.sess = tf.Session()\n",
        "    self.sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "  def getgraph(self):\n",
        "    tf.reset_default_graph()\n",
        "    self.initial()\n",
        "    \n",
        "    self.q_t = self.neuralnet(self.s_t) # Get q-values at s_t [1 x 4]\n",
        "    self.q_t1 = self.neuralnet(self.s_t1) # Get q-values at s_t+1 [1 x 4]\n",
        "    # next_a (a_t+1) will be chosen in the step function (evaluate and then feed back in)\n",
        "\n",
        "    \n",
        "    self._delta = self._r + self._g * self.q_t1[:, self.a_t1] - self.q_t[:, self.a_t]\n",
        "    self.q_loss = tf.square(self._delta)/2\n",
        "    \n",
        "    # Use SGD to find the variables\n",
        "    self.optimizer = tf.train.GradientDescentOptimizer(self._alpha).minimize(self.q_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1jZsPzCmDxAh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Analyse Results"
      ]
    },
    {
      "metadata": {
        "id": "xQkk8sMxE0N4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Run the cells below to train the tabular and neural SARSA agents and to generate plots.\n",
        "\n",
        "This trains the agents the Grid problem with an epsilon of 0.1.\n",
        "\n",
        "The plots below will show action values for each of the actions, as well as a state value defined by $v(s) = \\sum_a \\pi(a|s) q(s, a)$."
      ]
    },
    {
      "metadata": {
        "id": "GsNBHNZtHCPe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "cellView": "both",
        "outputId": "167ff13f-5fd6-44e8-815b-64f1f87e251f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524099978513,
          "user_tz": -60,
          "elapsed": 3187,
          "user": {
            "displayName": "JOY WU",
            "photoUrl": "//lh6.googleusercontent.com/-tPBEt0lFVJA/AAAAAAAAAAI/AAAAAAAABm0/dJFicuVmNrg/s50-c-k-no/photo.jpg",
            "userId": "118283881385645801877"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "grid = Grid()\n",
        "agent = Sarsa(number_of_states=grid._layout.size,\n",
        "              number_of_actions=4, \n",
        "              initial_state = grid.get_obs())\n",
        "run_experiment(grid, agent, int(1e5))\n",
        "q = agent.q_values.reshape(grid._layout.shape + (4,))\n",
        "plot_action_values(q)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcAAAAHBCAYAAAD+eWvWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd3e76a8510>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "K-JnvcP0mrxF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "de6f3632-9ec5-41ff-f9bd-2fe819b461c2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524100076493,
          "user_tz": -60,
          "elapsed": 96418,
          "user": {
            "displayName": "JOY WU",
            "photoUrl": "//lh6.googleusercontent.com/-tPBEt0lFVJA/AAAAAAAAAAI/AAAAAAAABm0/dJFicuVmNrg/s50-c-k-no/photo.jpg",
            "userId": "118283881385645801877"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "vision_size = 1\n",
        "grid = Grid(tabular=False, vision_size=vision_size)\n",
        "agent = NeuralSarsa(number_of_features=(2*vision_size + 1)**2,\n",
        "                    number_of_hidden=100,\n",
        "                    number_of_actions=4,\n",
        "                    initial_state=grid.get_obs(),\n",
        "                    step_size=0.01)\n",
        "run_experiment(grid, agent, int(1e5))\n",
        "h, w = grid._layout.shape\n",
        "obs = np.array([[grid.get_obs_at(x, y) for x in range(2, w-2)] for y in range(2, h-2)])\n",
        "qs = np.array([[[agent.q(o)[a] for a in range(4)] if o[vision_size,vision_size] == 0 else np.zeros((4,)) for o in ob] for ob in obs])\n",
        "plot_action_values(qs)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcAAAAHBCAYAAAD+eWvWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlwhAAICXCEAAgJf+Py43TayE4f/lAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd3e557c390>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "tmGFDriIPsGz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "64d5518f-afbc-4dea-cd2d-d036c8228c45",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524100184728,
          "user_tz": -60,
          "elapsed": 98217,
          "user": {
            "displayName": "JOY WU",
            "photoUrl": "//lh6.googleusercontent.com/-tPBEt0lFVJA/AAAAAAAAAAI/AAAAAAAABm0/dJFicuVmNrg/s50-c-k-no/photo.jpg",
            "userId": "118283881385645801877"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "vision_size = 2\n",
        "grid = Grid(tabular=False, vision_size=vision_size)\n",
        "agent = NeuralSarsa(number_of_features=(2*vision_size + 1)**2,\n",
        "                    number_of_hidden=100,\n",
        "                    number_of_actions=4,\n",
        "                    initial_state=grid.get_obs(),\n",
        "                    step_size=0.01)\n",
        "run_experiment(grid, agent, int(1e5))\n",
        "h, w = grid._layout.shape\n",
        "obs = np.array([[grid.get_obs_at(x, y) for x in range(2, w-2)] for y in range(2, h-2)])\n",
        "qs = np.array([[[agent.q(o)[a] for a in range(4)] if o[vision_size,vision_size] == 0 else np.zeros((4,)) for o in ob] for ob in obs])\n",
        "plot_action_values(qs)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcAAAAHBCAYAAAD+eWvWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd3e2e292d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "LGptHwE23lmP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Questions\n",
        "\n",
        "Consider the greedy policy with respect to the estimated values\n",
        "\n",
        "**[5 pts]** Which algorithm performed best?  Why?\n",
        "\n",
        "**Answer**: \n",
        "\n",
        "Tabular Sarsa performed the best since the environment is deterministic and the tabular can update the q values with greater precision compared to that using of neural network no cunts leave here till we find out what cunts did it.\n",
        "\n",
        "**[5 pts]** Is there a difference in the solution found by Neural Sarsa with a vision size of 1 (so 3x3 local observations), and a vision size of 2 (so 5x5 local observations)?  Why?\n",
        "\n",
        "**Answer**:\n",
        "\n",
        "There is no obvious difference between the two plots above.\n",
        "\n",
        "**[10 pts]** How could we improve the performance of the Neural Sarsa agent on this domain (for both vision sizes)?  Identify the main issue, and propose a concrete solution (in max 200 words).\n",
        "\n",
        "**[10 BONUS pts]** Implement your proposed improvement and show that it actually helps performance."
      ]
    }
  ]
}